# Complete Project Summary
## Evalence AI Security Testing Platform - Comprehensive Documentation

**Version**: 1.0.0  
**Last Updated**: January 2025  
**Status**: Production-Ready POC â†’ Enterprise Scaling Phase

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Project Overview](#project-overview)
3. [System Architecture](#system-architecture)
4. [Backend Components](#backend-components)
5. [Frontend Components](#frontend-components)
6. [Testing Modules](#testing-modules)
7. [Firewall Module](#firewall-module)
8. [Data Layer](#data-layer)
9. [API Endpoints](#api-endpoints)
10. [Configuration](#configuration)
11. [Technology Stack](#technology-stack)
12. [Features & Capabilities](#features--capabilities)
13. [Current Limitations](#current-limitations)
14. [Future Roadmap](#future-roadmap)

---

## Executive Summary

**Evalence** is a comprehensive AI Security Testing Platform that helps organizations identify and fix security vulnerabilities in their AI systems. The platform consists of two main components:

1. **Pre-Deployment Testing Suite**: Four security testing modules (Prompt Injection, Jailbreak, Data Extraction, Adversarial Attacks)
2. **Post-Deployment Firewall**: Real-time production guardrails (Input Guardrails, Output Evaluation, Threat Intelligence)

**Current State**: Production-ready POC with in-memory storage, ready for enterprise scaling with database layer and cloud infrastructure.

**Key Achievement**: Unified platform combining pre-deployment testing with post-deployment protection, with a planned Learning Engine to connect both.

---

## Project Overview

### Mission
To make AI systems safer by providing comprehensive, automated security testing and real-time protection that helps organizations identify and fix vulnerabilities before they can be exploited.

### Core Value Proposition
- **Pre-Deployment**: Test AI systems against real-world attack scenarios before production
- **Post-Deployment**: Real-time firewall protection in production environments
- **Unified Platform**: Single solution for both testing and protection
- **Continuous Learning**: Planned Learning Engine to connect testing results with firewall rules

### Target Customers
- AI/ML Companies
- Enterprise Organizations
- Financial Institutions
- Healthcare Organizations
- Government Agencies
- Security Consulting Firms
- AI Research Institutions

---

## System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Next.js)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Testing  â”‚  â”‚ Firewall â”‚  â”‚ Analyticsâ”‚  â”‚ Settings â”‚   â”‚
â”‚  â”‚ Modules  â”‚  â”‚ Modules  â”‚  â”‚ & Reportsâ”‚  â”‚          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    HTTP/REST API
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend API (FastAPI)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Auth   â”‚  â”‚  Testing â”‚  â”‚ Firewall  â”‚  â”‚   LLM    â”‚   â”‚
â”‚  â”‚ Service  â”‚  â”‚ Executor  â”‚  â”‚ Evaluator â”‚  â”‚  Client  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Testing       â”‚  â”‚  Firewall       â”‚  â”‚  Evaluation      â”‚
â”‚  Services      â”‚  â”‚  Services       â”‚  â”‚  Services        â”‚
â”‚                â”‚  â”‚                 â”‚  â”‚                  â”‚
â”‚  â€¢ Prompt Inj. â”‚  â”‚  â€¢ Input        â”‚  â”‚  â€¢ Semantic      â”‚
â”‚  â€¢ Jailbreak   â”‚  â”‚    Guardrails   â”‚  â”‚  â€¢ Structural    â”‚
â”‚  â€¢ Data Extr.  â”‚  â”‚  â€¢ Output Eval  â”‚  â”‚  â€¢ Rule-based    â”‚
â”‚  â€¢ Adversarial â”‚  â”‚  â€¢ Threat Intel â”‚  â”‚  â€¢ LLM Judge     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Storage  â”‚  â”‚  External APIs  â”‚  â”‚  Configuration â”‚
â”‚                â”‚  â”‚                 â”‚  â”‚                 â”‚
â”‚  â€¢ JSON Files  â”‚  â”‚  â€¢ OpenAI       â”‚  â”‚  â€¢ .env        â”‚
â”‚  â€¢ In-Memory   â”‚  â”‚  â€¢ Ollama       â”‚  â”‚  â€¢ Settings    â”‚
â”‚  â€¢ localStorageâ”‚  â”‚  â€¢ Judge Models â”‚  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Architecture (POC)
- **Storage**: In-memory dictionaries + JSON files + localStorage
- **Deployment**: Single server, no containerization
- **Scaling**: Not horizontally scalable
- **Database**: None (planned for enterprise scaling)

### Target Architecture (Enterprise)
- **Storage**: PostgreSQL + MongoDB + Redis + Vector DB
- **Deployment**: Kubernetes/ECS, containerized
- **Scaling**: Auto-scaling, load balancing
- **Database**: Full database layer with backups

---

## Backend Components

### 1. API Gateway (`backend/api/main.py`)

**Purpose**: Main FastAPI application, entry point for all API requests

**Key Features**:
- CORS middleware configuration
- Authentication endpoints
- Test execution endpoints (4 modules)
- Firewall endpoints (input evaluation, chat)
- Health check endpoint
- Error handling and validation

**Endpoints**: 22 total endpoints (see API Endpoints section)

### 2. Authentication Service (`backend/services/auth.py`)

**Purpose**: User authentication and session management

**Features**:
- Static credential validation (POC)
- Session token generation
- Session validation
- Session deletion (logout)

**Current Implementation**:
- In-memory session storage
- Simple token-based authentication
- **Future**: Database-backed, JWT tokens, OAuth

### 3. Test Executor (`backend/services/test_executor.py`)

**Purpose**: Orchestrates test execution for all 4 testing modules

**Features**:
- Background task execution
- Progress tracking
- Result aggregation
- Error handling

**Supported Test Types**:
1. Prompt Injection
2. Jailbreak
3. Data Extraction
4. Adversarial Attacks

### 4. Testing Services

#### 4.1 Prompt Injection Service (`backend/services/prompt_injection/`)

**Structure**:
```
prompt_injection/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ evaluator.py          # Main evaluator
â”‚   â”œâ”€â”€ factory.py            # Evaluation factory
â”‚   â”œâ”€â”€ layer1_semantic.py    # Semantic analysis
â”‚   â”œâ”€â”€ layer1_structural.py # Structural analysis
â”‚   â”œâ”€â”€ baseline_manager.py  # Baseline patterns
â”‚   â”œâ”€â”€ confidence_calculator.py
â”‚   â”œâ”€â”€ false_positive_detector.py
â”‚   â”œâ”€â”€ data_leakage_detector.py
â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”œâ”€â”€ signal_aggregator.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ types.py
â””â”€â”€ IMPLEMENTATION_SUMMARY.md
```

**Capabilities**:
- System prompt extraction detection
- Instruction override detection
- Role-playing attack detection
- Delimiter attack detection
- Multi-step attack detection

#### 4.2 Jailbreak Service (`backend/services/jailbreak/`)

**Structure**: Similar to prompt_injection

**Capabilities**:
- Role-playing jailbreak detection
- Hypothetical scenario detection
- Developer mode detection
- Research context detection
- Creative writing jailbreak detection

#### 4.3 Data Extraction Service (`backend/services/data_extraction/`)

**Structure**: Similar to prompt_injection

**Capabilities**:
- Training data extraction detection
- System prompt extraction
- API key extraction detection
- Personal information extraction
- Proprietary information extraction

#### 4.4 Adversarial Attacks Service (`backend/services/adversarial_attacks/`)

**Structure**: Similar to prompt_injection

**Capabilities**:
- Input manipulation detection
- Context poisoning detection
- Model confusion detection
- Transfer attack detection

### 5. Firewall Services

#### 5.1 Input Guardrails (`backend/services/firewall/input_guardrails/`)

**Purpose**: Real-time evaluation of user inputs before sending to LLM

**Structure**:
```
input_guardrails/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ evaluator.py              # Main orchestrator
â”œâ”€â”€ types.py                  # Data structures
â”œâ”€â”€ config.py                 # Configuration
â”œâ”€â”€ response_messages.py       # Static response messages
â”œâ”€â”€ rate_limiter.py           # Rate limiting
â”œâ”€â”€ pii_detector.py           # PII detection
â”œâ”€â”€ harmful_content_detector.py
â”œâ”€â”€ prompt_injection_detector.py
â”œâ”€â”€ jailbreak_detector.py
â”œâ”€â”€ encoding_detector.py      # Base64, URL encoding
â”œâ”€â”€ context_aware_detector.py # Conversation history
â””â”€â”€ IMPLEMENTATION_SUMMARY.md
```

**Detection Layers** (in priority order):
1. **Rate Limiting**: Per user/IP/session limits
2. **Encoding Detection**: Base64, URL encoding detection and decoding
3. **Harmful Content**: Violence, illegal, hate speech
4. **Prompt Injection**: Instruction override attempts
5. **Jailbreak**: Safety restriction bypass attempts
6. **PII Detection**: SSN, credit cards, emails, phones
7. **Context-Aware**: Conversation history analysis

**Key Features**:
- Multi-layer detection (7 layers)
- Context-aware validation (5-message history)
- Encoding detection (Base64, URL)
- Real-time evaluation (<50ms target)
- Static response messages
- Confidence scoring
- False positive reduction

**Performance**:
- Total latency: ~15-30ms
- Encoding detection: ~2-5ms
- Context-aware: ~5-10ms
- Memory: Minimal (in-memory history)

### 6. Evaluation Services

**Multi-Layer Evaluation System** (used by all testing modules):

#### Layer 1: Fast Automated Analysis
- **Semantic Similarity**: Compares responses to safe/vulnerable baselines using embeddings
- **Structural Pattern**: Detects specific words, phrases, patterns

#### Layer 2: Rule-Based Deep Analysis
- Domain-specific security rules
- Context-aware validation
- False positive detection

#### Layer 3: Advanced AI Evaluation
- LLM-as-a-Judge (GPT-4o-mini or Ollama)
- Detailed reasoning
- Complex edge case handling

#### Ensemble Evaluation
- Aggregates signals from all layers
- Weighted voting
- Confidence scoring

### 7. LLM Client (`backend/utils/llm_client.py`)

**Purpose**: Unified interface for LLM API calls

**Supported Providers**:
- OpenAI (GPT-3.5, GPT-4, GPT-4o-mini)
- Ollama Cloud (glm-4.6:cloud, gpt-oss:20b-cloud)
- OpenAI-compatible APIs

**Features**:
- Async/await support
- Error handling
- Retry logic
- Token management

### 8. Configuration (`backend/config/settings.py`)

**Environment Variables**:
- `OPENAI_API_KEY`: OpenAI API key
- `OLLAMA_API_KEY`: Ollama API key
- `OLLAMA_HOST`: Ollama host URL
- `OLLAMA_FIREWALL_MODEL`: Model for firewall chat (gpt-oss:20b-cloud)
- `JUDGE_MODEL`: Model for evaluation (glm-4.6:cloud)
- `TARGET_MODEL`: Default model for testing
- `USE_OLLAMA_FOR_EVALUATION`: Boolean flag
- `CORS_ORIGINS`: CORS configuration
- `MAX_PROMPTS_PI/JB/DE/ADVERSARIAL`: Test limits

---

## Frontend Components

### 1. Application Structure

**Framework**: Next.js 15 (React-based)  
**Language**: TypeScript  
**UI Library**: Shadcn UI + Radix UI  
**Styling**: Tailwind CSS

### 2. Pages & Routes

#### Main Dashboard (`/dashboard`)
- Overview with module cards
- Statistics dashboard
- Quick access to all modules

#### Testing Modules
- `/dashboard/prompt-injection` - Prompt Injection testing
- `/dashboard/jailbreak` - Jailbreak testing
- `/dashboard/data-extraction` - Data Extraction testing
- `/dashboard/adversarial` - Adversarial Attacks testing

#### Firewall Modules
- `/dashboard/firewall` - Firewall dashboard
- `/dashboard/firewall/input-guardrails` - Input Guardrails UI
- `/dashboard/firewall/output-evaluation` - Output Evaluation UI
- `/dashboard/firewall/threat-intelligence` - Threat Intelligence UI
- `/dashboard/firewall/incident-response` - Incident Response UI
- `/dashboard/firewall/analytics` - Analytics dashboard
- `/dashboard/firewall/chat` - Chat interface for testing firewall

#### Other Pages
- `/dashboard/evals` - Evaluations & Analytics
- `/dashboard/reports` - Test Reports
- `/dashboard/settings` - Settings & Configuration

### 3. Components

#### UI Components (`frontend/components/ui/`)
- **Shadcn UI Components**: Button, Card, Dialog, Table, Tabs, etc.
- **Firewall Components**: 
  - `firewall-dashboard-content.tsx`
  - `input-guardrails-content.tsx`
  - `output-evaluation-content.tsx`
  - `threat-intelligence-content.tsx`
  - `incident-response-content.tsx`
  - `analytics-content.tsx`
- **Firewall Chat**: `firewall/chat-content.tsx`

#### Layout Components
- `dashboard/layout.tsx` - Main dashboard layout with sidebar
- Sidebar navigation with modules
- Breadcrumb navigation
- User menu

### 4. API Integration (`frontend/lib/`)

#### API Configuration (`api-config.ts`)
- Centralized endpoint configuration
- Environment-based URLs
- API versioning

#### Firewall API (`firewall-api.ts`)
- `evaluateInput()` - Evaluate input through guardrails
- `getFirewallStats()` - Get firewall statistics
- `getBlockedInputs()` - Get blocked inputs list
- `chatWithFirewall()` - Chat with LLM through firewall

#### State Management
- React Hooks (useState, useEffect)
- localStorage for persistence
- Real-time updates via StorageEvent

### 5. Features

#### Testing Modules UI
- Test configuration forms
- Real-time progress tracking
- Results visualization
- Download reports
- Test history

#### Input Guardrails UI
- Statistics cards (blocked/allowed today, block rate, etc.)
- Detection rules configuration (toggles, sliders)
- Recent blocks live feed
- Test input functionality
- Details dialog for blocked inputs
- Real-time updates from chat module

#### Chat Module
- Chat interface (ChatGPT-like)
- Real-time firewall evaluation
- Blocked message display
- Conversation history
- Integration with Input Guardrails analytics

---

## Testing Modules

### 1. Prompt Injection Testing

**Purpose**: Test AI's resistance to instruction manipulation attacks

**Test Categories**:
- System prompt extraction
- Instruction override
- Role-playing attacks
- Delimiter attacks
- Multi-step attacks

**Dataset**: `data/modules/prompt_injection/`
- `prompt_injection_comprehensive.json` (14,000+ samples)
- `prompt_injection_test_30.json` (30 test samples)

**Evaluation**:
- Multi-layer evaluation (semantic, structural, LLM judge)
- Detection rate calculation
- Confidence scoring
- False positive detection

### 2. Jailbreak Testing

**Purpose**: Test AI's ability to maintain safety restrictions

**Test Categories**:
- Role-playing jailbreaks
- Hypothetical scenarios
- Developer mode
- Research context
- Creative writing

**Dataset**: `data/modules/jailbreak/`
- `jailbreak_comprehensive.json` (14,000+ samples)
- `jailbreak_test_30.json` (30 test samples)

**Evaluation**: Similar to Prompt Injection

### 3. Data Extraction Testing

**Purpose**: Test AI's protection of sensitive data

**Test Categories**:
- Training data extraction
- System prompt extraction
- API key extraction
- Personal information extraction
- Proprietary information extraction

**Dataset**: `data/modules/data_extraction/`
- `data_extraction_comprehensive.json` (14,000+ samples)
- `data_extraction_test_30.json` (30 test samples)

**Evaluation**: Similar to Prompt Injection

### 4. Adversarial Attacks Testing

**Purpose**: Test AI's robustness against sophisticated attacks

**Test Categories**:
- Input manipulation
- Context poisoning
- Model confusion
- Transfer attacks

**Dataset**: `data/modules/adversarial_attacks/`
- `adversarial_attacks_comprehensive.json` (14,000+ samples)
- `adversarial_attacks_test_30.json` (30 test samples)

**Evaluation**: Similar to Prompt Injection

### Test Execution Flow

```
1. User configures test (module, model, API key)
2. System loads dataset (comprehensive or test)
3. For each sample:
   a. Send prompt to target LLM
   b. Capture response
   c. Evaluate response (multi-layer)
   d. Store results
4. Aggregate results
5. Generate report
6. Display results in UI
```

---

## Firewall Module

### 1. Input Guardrails

**Purpose**: Evaluate user inputs BEFORE sending to LLM

**Detection Layers** (Priority Order):

1. **Rate Limiting**
   - Per user/IP/session limits
   - Burst protection
   - Throttling

2. **Encoding Detection**
   - Base64 detection and decoding
   - URL encoding detection and decoding
   - Auto re-check decoded content

3. **Harmful Content**
   - Violence detection
   - Illegal activities
   - Hate speech
   - Context-aware (educational, medical, etc.)

4. **Prompt Injection**
   - Instruction override attempts
   - System prompt extraction
   - Programming context awareness

5. **Jailbreak**
   - Safety restriction bypass
   - Role-playing attempts
   - Hypothetical scenarios

6. **PII Detection**
   - SSN detection
   - Credit card detection
   - Email detection
   - Phone number detection
   - Sanitization option

7. **Context-Aware**
   - Conversation history (5 messages)
   - Educational context detection
   - Multi-turn attack detection
   - Gradual escalation detection

**Decision Types**:
- `ALLOWED`: Input is safe
- `BLOCKED`: Input contains threat
- `SANITIZED`: PII removed, input allowed
- `THROTTLED`: Rate limit exceeded

**Response Messages**: Static, predefined messages for each threat type

**Performance**:
- Target latency: <50ms
- Actual latency: ~15-30ms
- Memory: Minimal (in-memory history)

### 2. Output Evaluation (Planned)

**Purpose**: Evaluate LLM responses AFTER generation

**Planned Features**:
- Response safety evaluation
- Content moderation
- Data leakage detection
- Quality assessment

### 3. Threat Intelligence (Planned)

**Purpose**: Threat pattern detection and sharing

**Planned Features**:
- Pattern recognition
- Threat database
- Intelligence sharing
- Pattern matching

### 4. Incident Response (Planned)

**Purpose**: Manage security incidents

**Planned Features**:
- Incident tracking
- Response workflows
- Alerting
- Reporting

### 5. Analytics (Planned)

**Purpose**: Monitoring and analytics

**Planned Features**:
- Real-time dashboards
- Statistics aggregation
- Trend analysis
- Reporting

### 6. Chat Module

**Purpose**: Test firewall with chat interface

**Features**:
- ChatGPT-like interface
- Real-time firewall evaluation
- Blocked message display
- Conversation history
- Integration with Input Guardrails analytics

**LLM**: Uses Ollama `gpt-oss:20b-cloud` model

---

## Data Layer

### Current State (POC)

#### Storage Mechanisms

1. **In-Memory Storage**
   - `test_sessions: Dict` in `backend/api/main.py`
   - Active test sessions
   - Lost on server restart

2. **File-Based Storage**
   - JSON files in `data/` directory
   - Test datasets (comprehensive and test versions)
   - Results stored in `results/` directory

3. **Frontend Storage**
   - `localStorage` for test history
   - `localStorage` for firewall analytics
   - Browser-specific, not synced

#### Data Structures

**Test Datasets**:
- `data/modules/prompt_injection/`
- `data/modules/jailbreak/`
- `data/modules/data_extraction/`
- `data/modules/adversarial_attacks/`

Each module has:
- `*_comprehensive.json` (14,000+ samples)
- `*_test_30.json` (30 test samples)
- `transform_*.py` (data transformation scripts)

**Test Results**:
- Stored in `test_sessions` dictionary
- JSON format
- Includes: captured responses, evaluated responses, metrics

**Firewall Data**:
- Blocked inputs stored in `localStorage`
- Statistics stored in `localStorage`
- Real-time updates via StorageEvent

### Target State (Enterprise)

#### Database Architecture

**PostgreSQL** (Primary):
- Users & organizations
- Test sessions metadata
- Firewall evaluations
- Prompt bank
- Threat patterns

**MongoDB** (Document Store):
- Large test result documents
- Detailed evaluation data
- Configuration snapshots

**Redis** (Caching):
- Active test sessions
- Real-time stats
- Rate limiting counters
- Conversation history

**Vector Database** (Threat Intelligence):
- Threat pattern embeddings
- Similarity search
- Pattern matching

---

## API Endpoints

### Base URL
```
http://localhost:8000/api/v1
```

### Authentication Endpoints

1. **POST** `/api/v1/auth/login`
   - User login
   - Returns session token

2. **POST** `/api/v1/auth/logout`
   - User logout
   - Invalidates session

3. **POST** `/api/v1/auth/verify`
   - Verify token validity
   - Returns user info

### Testing Endpoints

#### Prompt Injection
1. **POST** `/api/v1/test/prompt-injection/start` - Start test
2. **GET** `/api/v1/test/prompt-injection/{test_id}/status` - Get status
3. **GET** `/api/v1/test/prompt-injection/{test_id}/results` - Get results
4. **GET** `/api/v1/test/prompt-injection/{test_id}/download` - Download report

#### Jailbreak
1. **POST** `/api/v1/test/jailbreak/start` - Start test
2. **GET** `/api/v1/test/jailbreak/{test_id}/status` - Get status
3. **GET** `/api/v1/test/jailbreak/{test_id}/results` - Get results
4. **GET** `/api/v1/test/jailbreak/{test_id}/download` - Download report

#### Data Extraction
1. **POST** `/api/v1/test/data-extraction/start` - Start test
2. **GET** `/api/v1/test/data-extraction/{test_id}/status` - Get status
3. **GET** `/api/v1/test/data-extraction/{test_id}/results` - Get results
4. **GET** `/api/v1/test/data-extraction/{test_id}/download` - Download report

#### Adversarial Attacks
1. **POST** `/api/v1/test/adversarial-attacks/start` - Start test
2. **GET** `/api/v1/test/adversarial-attacks/{test_id}/status` - Get status
3. **GET** `/api/v1/test/adversarial-attacks/{test_id}/results` - Get results
4. **GET** `/api/v1/test/adversarial-attacks/{test_id}/download` - Download report

### Firewall Endpoints

1. **POST** `/api/v1/firewall/evaluate/input`
   - Evaluate input through guardrails
   - Returns decision (allowed/blocked/sanitized/throttled)

2. **POST** `/api/v1/firewall/chat`
   - Chat with LLM through firewall
   - Evaluates input before sending to LLM
   - Returns LLM response or error if blocked

### Health Check

1. **GET** `/health`
   - Health check endpoint
   - Returns service status

### API Documentation

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

---

## Configuration

### Environment Variables

#### Backend (`.env`)
```bash
# OpenAI Configuration
OPENAI_API_KEY=sk-...

# Ollama Configuration
OLLAMA_API_KEY=...
OLLAMA_HOST=https://api.ollama.com
OLLAMA_FIREWALL_MODEL=gpt-oss:20b-cloud
JUDGE_MODEL=glm-4.6:cloud
USE_OLLAMA_FOR_EVALUATION=true

# Target Model
TARGET_MODEL=gpt-3.5-turbo

# Test Limits
MAX_PROMPTS_PI=30
MAX_PROMPTS_JB=30
MAX_PROMPTS_DE=30
MAX_PROMPTS_ADVERSARIAL=30

# CORS
CORS_ORIGINS=["http://localhost:3000"]
```

#### Frontend
- API URL configuration in `lib/api-config.ts`
- Environment-based configuration

### Configuration Files

#### Backend
- `backend/config/settings.py` - Application settings
- `backend/pytest.ini` - Test configuration

#### Frontend
- `frontend/next.config.mjs` - Next.js configuration
- `frontend/tailwind.config.ts` - Tailwind CSS configuration
- `frontend/tsconfig.json` - TypeScript configuration
- `frontend/package.json` - Dependencies

---

## Technology Stack

### Backend

**Framework**: FastAPI (Python 3.11+)
- Fast, modern, async-capable
- Automatic API documentation
- Type validation with Pydantic

**Key Libraries**:
- `fastapi` - Web framework
- `uvicorn` - ASGI server
- `pydantic` - Data validation
- `openai` - OpenAI SDK
- `python-dotenv` - Environment management
- `pytest` - Testing framework

**AI/ML**:
- OpenAI API (GPT models)
- Ollama Cloud API (glm-4.6:cloud, gpt-oss:20b-cloud)
- Embeddings (OpenAI or local)

### Frontend

**Framework**: Next.js 15
- React-based
- Server-side rendering
- TypeScript

**UI Libraries**:
- Shadcn UI - Component library
- Radix UI - Accessible primitives
- Tailwind CSS - Utility-first styling

**Key Libraries**:
- `react` - UI library
- `next` - Framework
- `typescript` - Type safety
- `lucide-react` - Icons
- `recharts` - Charts (if used)

### Infrastructure (Current)

**Server**: Uvicorn (ASGI)
**Storage**: In-memory + JSON files
**Deployment**: Single server

### Infrastructure (Target)

**Cloud**: AWS/Azure/GCP
**Containers**: Docker + Kubernetes/ECS
**Database**: PostgreSQL + MongoDB + Redis
**Message Queue**: Kafka/RabbitMQ
**Monitoring**: Prometheus + Grafana

---

## Features & Capabilities

### Testing Suite Features

1. **Four Testing Modules**
   - Prompt Injection
   - Jailbreak
   - Data Extraction
   - Adversarial Attacks

2. **Multi-Layer Evaluation**
   - Semantic similarity analysis
   - Structural pattern analysis
   - Rule-based analysis
   - LLM-as-a-Judge evaluation
   - Ensemble evaluation

3. **Comprehensive Datasets**
   - 14,000+ samples per module (comprehensive)
   - 30 samples per module (test)
   - Real-world attack scenarios

4. **Real-Time Progress Tracking**
   - Live status updates
   - Progress percentage
   - Current step indication

5. **Detailed Reports**
   - Summary statistics
   - Detailed findings
   - Confidence scores
   - Recommendations
   - Downloadable JSON reports

### Firewall Features

1. **Input Guardrails**
   - 7 detection layers
   - Real-time evaluation (<50ms)
   - Context-aware validation
   - Encoding detection
   - Static response messages

2. **Chat Module**
   - ChatGPT-like interface
   - Real-time firewall protection
   - Blocked message display
   - Analytics integration

3. **Analytics** (Frontend)
   - Statistics cards
   - Recent blocks feed
   - Real-time updates
   - Test input functionality

### User Experience Features

1. **Modern UI**
   - Clean, intuitive interface
   - Responsive design
   - Real-time updates
   - Loading states
   - Error handling

2. **Dashboard**
   - Overview of all modules
   - Statistics
   - Quick access
   - Status indicators

3. **Navigation**
   - Sidebar navigation
   - Breadcrumb trails
   - Module grouping
   - Search (planned)

---

## Current Limitations

### Storage & Persistence

1. **No Database Layer**
   - In-memory storage (lost on restart)
   - File-based storage (not scalable)
   - No querying capability
   - No transactions

2. **No Backup Strategy**
   - No automated backups
   - No disaster recovery
   - Data loss risk

3. **Limited Scalability**
   - Single server deployment
   - No horizontal scaling
   - No load balancing

### Authentication & Security

1. **Simple Authentication**
   - Static credentials (POC)
   - No JWT tokens
   - No OAuth
   - No MFA

2. **Session Management**
   - In-memory sessions
   - No persistence
   - Lost on restart

### Features

1. **Incomplete Firewall Modules**
   - Input Guardrails: âœ… Complete
   - Output Evaluation: âŒ Not implemented
   - Threat Intelligence: âŒ Not implemented
   - Incident Response: âŒ Not implemented
   - Analytics: âŒ Partial (frontend only)

2. **No Learning Engine**
   - Testing and Firewall not connected
   - No automatic rule generation
   - No pattern learning

3. **Limited Data Pipeline**
   - Manual prompt bank updates
   - No automated ingestion
   - No version control

### Infrastructure

1. **No Cloud Deployment**
   - Local development only
   - No containerization
   - No CI/CD

2. **No Monitoring**
   - No observability
   - No logging aggregation
   - No metrics collection

---

## Future Roadmap

### Phase 1: Database & Infrastructure (Months 1-2)

**Goals**:
- Implement database layer (PostgreSQL, MongoDB, Redis)
- Migrate existing data
- Set up cloud infrastructure
- Containerize services

**Deliverables**:
- Database schema implemented
- Data migration completed
- Basic cloud deployment
- Docker containers

### Phase 2: Microservices (Months 3-4)

**Goals**:
- Break into microservices
- Implement service communication
- Add load balancing
- Auto-scaling

**Deliverables**:
- Microservices architecture
- Kubernetes/ECS deployment
- Auto-scaling configured
- Service mesh (optional)

### Phase 3: Data Pipeline (Months 5-6)

**Goals**:
- Automated prompt bank updates
- Multiple data sources
- Version control
- Update propagation

**Deliverables**:
- Data ingestion service
- Kafka/Message Queue
- Processing pipeline
- Automated updates

### Phase 4: Learning Engine (Months 7-8)

**Goals**:
- Connect testing and firewall
- Automatic rule generation
- Pattern learning
- Adaptive optimization

**Deliverables**:
- Learning Engine service
- Rule generation
- Pattern recognition
- Adaptive thresholds

### Phase 5: Advanced Features (Months 9-12)

**Goals**:
- Complete firewall modules
- Vector database integration
- Advanced analytics
- Multi-region deployment

**Deliverables**:
- Output Evaluation
- Threat Intelligence
- Incident Response
- Full Analytics
- Vector search
- Multi-region support

---

## Summary

### What We Have

âœ… **4 Testing Modules**: Prompt Injection, Jailbreak, Data Extraction, Adversarial Attacks  
âœ… **Multi-Layer Evaluation**: Semantic, Structural, Rule-based, LLM Judge  
âœ… **Input Guardrails**: 7 detection layers, real-time protection  
âœ… **Chat Module**: Test firewall with chat interface  
âœ… **Modern UI**: Next.js frontend with real-time updates  
âœ… **Comprehensive Datasets**: 14,000+ samples per module  
âœ… **API**: RESTful API with 22 endpoints  

### What We're Missing

âŒ **Database Layer**: No persistent storage  
âŒ **Cloud Infrastructure**: No production deployment  
âŒ **Complete Firewall**: Only Input Guardrails implemented  
âŒ **Learning Engine**: Testing and Firewall not connected  
âŒ **Data Pipeline**: Manual prompt bank updates  
âŒ **Monitoring**: No observability  

### What's Next

ğŸš€ **Enterprise Scaling**: Database, cloud, microservices  
ğŸš€ **Learning Engine**: Connect testing and firewall  
ğŸš€ **Complete Firewall**: All modules implemented  
ğŸš€ **Data Pipeline**: Automated prompt bank updates  
ğŸš€ **Advanced Features**: Vector DB, analytics, multi-region  

---

**Document Status**: Complete  
**Last Updated**: January 2025  
**Version**: 1.0.0

